# -*- coding: utf-8 -*-
"""Web_scraping.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j8Qv4_SDoIsKAC6WnQDDCXgnWAtz6ORh
"""

!pip install requests beautifulsoup4

import requests
from bs4 import BeautifulSoup
import pandas as pd

def scrape_world_bank_data():
    # Define the URL of the World Bank Evaluation and Ratings page
    url = "https://ieg.worldbankgroup.org/data"

    # Send an HTTP GET request to the URL
    response = requests.get(url)

    # Check if the request was successful (status code 200)
    if response.status_code == 200:
        # Parse the HTML content of the page using BeautifulSoup
        soup = BeautifulSoup(response.content, "html.parser")

        # Extract the data you need from the HTML
        # (Replace this with your specific scraping logic)
        data = []

        # Example: Scraping all table rows and columns
        table = soup.find("table")
        rows = table.find_all("tr")
        for row in rows:
            cols = row.find_all("td")
            cols = [col.get_text(strip=True) for col in cols]
            data.append(cols)

        # Convert the data to a DataFrame (for further processing)
        df = pd.DataFrame(data)

        # Return the DataFrame
        return df

    else:
        print("Failed to fetch data. Status code:", response.status_code)
        return None

df_world_bank_data = scrape_world_bank_data()

# Example: Save the DataFrame to a CSV file
df_world_bank_data.to_csv("world_bank_data.csv", index=False)